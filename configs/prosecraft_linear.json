{
    "layers": 28,
    "d_model": 4096,
    "n_heads": 16,
    "n_vocab": 50400,
    "norm": "layernorm",
    "pe": "rotary",
    "pe_rotary_dims": 64,
  
    "seq": 2048,
    "cores_per_replica": 8,
    "per_replica_batch": 1,
    "gradient_accumulation_steps": 32,
  
    "warmup_steps": 200,
    "anneal_steps": 43120,
    "lr": 2e-5,
    "end_lr": 1e-8,
    "weight_decay": 0.1,
    "total_steps": 43195,
  
    "tpu_size": 8,
  
    "bucket": "prosecraft-storage",
    "model_dir": "prosecraft_linear",
  
    "train_set": "prosecraft_ft.train.index",
    "val_set": {
        "prosecraft_val_ft":"prosecraft_ft.val.index"
    },
    "eval_harness_tasks": [
    ],
    "val_batches": 2000,
    "val_every": 500,
    "ckpt_every": 1000,
    "keep_every": 5000,
  
    "name": "prosecraft_linear",
    "comment": "200 step warmup followed by linear decay - linear_onecycle_schedule(total_steps, lr, 0.0046, 1.0, 100.0, 10000). Training using the shuffled train dataset, with the old and new val datasets, 1,382,217 tokens / 32 batch size == 43195 steps",

    "prompts_path": "prompts/prompts.csv",
    "n_repeats": 1,
    "top_p": 0.9,
    "temp": 1.0
  }
  